{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MDclustering \n",
    "#### An attempt of making data analysis easier and quicker for many MD people\n",
    "\n",
    "## MAIN GOAL\n",
    "To do analysis of MD trajectory on a more abstract level. Instead of having to talk about specific atoms and their corresponding position and residue members. We often would like to talk about properties on a much more abstract level, such as the diffusion of a certain aggregate of particles, or talk about the leaflets of lipid assemblies. Current methods for leaflet identification often imply geometrical arguments  on every residue, which can quickly become very expensive. Here we present a mixture of voxel and graph based selection methods to obtain information about dynamic clusters at a (hopefully) realtime speed.\n",
    "\n",
    "### Clustering\n",
    "#### CONTOURS\n",
    "Contours are meant for analysis on the behaviour of clusters in a cheaper dimensionality. They could be enough to uniquely identify a cluster e.g. the number of particles present and the voxel space contour size (not exactly the real size, but often close enough).\n",
    "\n",
    "#### VOLUMES\n",
    "Volumes give you a more robust manner of selection which will for sure include all the particles you need for high resolution analysis. Combining layers of volumes and contours often can dramatically reduce the degrees of freedom in your data set, without loosing any particles on the way. Hopefully we will demonstrate this for the automatic leaflet detection in a crowded membrane space (all forms of lipid cluster states, such as: adhesed, semi-fused, fused and seperated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pbcpy.base import pbcarray # needed for pbc clustering\n",
    "import MDAnalysis as mda\n",
    "import numpy as np\n",
    "import copy\n",
    "#import nglview as nv\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "# allows for realtime plot rendering in notebook\n",
    "#%matplotlib notebook\n",
    "import itertools\n",
    "import collections\n",
    "import datetime\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_config(config_file='test_files/MDclustering.inp', verbose=False):\n",
    "    \"\"\"\n",
    "    A simple way to set default clustering settings.\n",
    "    \"\"\"\n",
    "    file_is_present = os.path.isfile(config_file) \n",
    "    if file_is_present:\n",
    "        exec(open(config_file).read())\n",
    "        if verbose:\n",
    "            with open(config_file) as f:\n",
    "                document = f.readlines()\n",
    "            print('The following settings will be used for the clustering.\\n')\n",
    "            for line in document:\n",
    "                print(line.strip())\n",
    "            print()\n",
    "    else:\n",
    "        print(\"Please create an input file (test_files/MDclustering.inp) with the following format:\\n\\n\\\n",
    "resolution  = 1\\n\\\n",
    "density     = 0.01\\n\\\n",
    "inv_density = False\\n\\\n",
    "min_cluster_size = 1\\n\")\n",
    "        sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### This is where it all happens\n",
    "def generate_explicit_matrix(array, resolution, density, specified_dim = False, \n",
    "                             inv_density = False, no_zero = True, verbose = False):\n",
    "    \"\"\"Takes a compressed 3d matrix and returns it as an explicit 3d matrix.\n",
    "    The resolution is the relative bin size. A tuple of 3 can be used to speify the\n",
    "    binning dimensions  in nm. It assumes your box has cubic PBC! Density can be used to \n",
    "    specify a minimum voxel density to be added to the output matrix. The inv_density can\n",
    "    be set to true to specify a maximum density. The no_zero flag will even under the inv_density\n",
    "    setting not return the elements containing 0 elements.\"\"\"\n",
    "    # we want to refer to the unmodified array for the dictionary entries later on\n",
    "    array_original = copy.copy(array)\n",
    "    # find the extremes to determine the final size of the explicit binned matrix\n",
    "    x_max, y_max, z_max = np.max(array[:,0]), np.max(array[:,1]), np.max(array[:,2])\n",
    "    if not specified_dim:\n",
    "        limits = np.array([x_max, y_max, z_max])\n",
    "    else:\n",
    "        limits = np.array(specified_dim)\n",
    "    # adapting the binning to the resolution\n",
    "    limits = limits/resolution\n",
    "    limits_ints = np.array(np.round(limits), dtype=int)\n",
    "    # making the explicit matrix\n",
    "    explicit_matrix = np.zeros(limits_ints)\n",
    "    # converting the data points\n",
    "    array_original = array\n",
    "    array = copy.copy(array_original)\n",
    "    array = array/resolution # convert data to bins\n",
    "    # creating a dicitonary with the atoms inside and the xyz coodirdiantes as keys\n",
    "    voxel2atoms = collections.defaultdict(list)\n",
    "    # adding each poin to the explicit matrix also cubic PBC!!!\n",
    "    for idx, point in enumerate(array):\n",
    "        # warning this implements cubic PBC!!! A similar trick can be done for others\n",
    "        x = round(point[0] % (limits_ints[0]-1)).astype(int)\n",
    "        y = round(point[1] % (limits_ints[1]-1)).astype(int)\n",
    "        z = round(point[2] % (limits_ints[2]-1)).astype(int)\n",
    "        #print(x, type(x), y, type(y), z ,type(z))\n",
    "        explicit_matrix[x, y, z] += 1\n",
    "        # mapping atoms to voxels\n",
    "        key = 'x{}y{}z{}'.format(x, y, z)\n",
    "        voxel2atoms[key].append(idx)\n",
    "    mean = explicit_matrix[explicit_matrix > 0].flatten().mean()\n",
    "    if verbose:\n",
    "        print('The average bin density is {:.2f}'.format(mean))\n",
    "    # clipping the matrix using the specified density or the inverse\n",
    "    if inv_density:\n",
    "        if no_zero:\n",
    "            explicit_matrix[explicit_matrix == 0 ] = density*mean + 1\n",
    "        explicit_matrix[explicit_matrix <= density*mean] = 1\n",
    "        explicit_matrix[explicit_matrix > density*mean] = 0 \n",
    "    else:\n",
    "        explicit_matrix[explicit_matrix < density*mean] = 0 \n",
    "        explicit_matrix[explicit_matrix >= density*mean] = 1\n",
    "    return explicit_matrix, voxel2atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smear_3d_matrix(array, pbc = True):\n",
    "    \"\"\"Takes an explicit array and smears it over the axes. This is like\n",
    "    a running average in 3D. It returns the smeared array as a new array.\n",
    "    By default the pbc is taken to be cubic, this can be turned off.\n",
    "    \n",
    "    !!! the smearing does not take pbc into account yet !!!\"\"\"\n",
    "    shift = 1\n",
    "    # making the matrix one bigger to prevent problems later on\n",
    "    #dimensions = np.array(array.shape)+np.array((2, 2, 2))\n",
    "    #array_empty = np.zeros(dimensions)\n",
    "    #array_empty[1:-1,1:-1,1:-1] = array\n",
    "    occupancy_mask = copy.copy(array)\n",
    "    # inverting the matrix to get the inner boundaries\n",
    "    occupancy_mask = np.array(np.logical_not(occupancy_mask),dtype=float)\n",
    "    # smearing the matrix\n",
    "    blurred_matrix = copy.copy(occupancy_mask)\n",
    "    blurred_matrix[shift:] += occupancy_mask[:-shift]\n",
    "    blurred_matrix[:-shift] += occupancy_mask[shift:]\n",
    "    blurred_matrix[:,shift:] += occupancy_mask[:,:-shift]\n",
    "    blurred_matrix[:,:-shift] += occupancy_mask[:,shift:]\n",
    "    blurred_matrix[:,:,shift:] += occupancy_mask[:,:,:-shift]\n",
    "    blurred_matrix[:,:,:-shift] += occupancy_mask[:,:,shift:]\n",
    "    # smearing the pbc boundaries for cubic pbc\n",
    "    if pbc:\n",
    "        blurred_matrix[0] += occupancy_mask[-1]\n",
    "        blurred_matrix[-1] += occupancy_mask[0]\n",
    "        blurred_matrix[:,0] += occupancy_mask[:,-1]\n",
    "        blurred_matrix[:,-1] += occupancy_mask[:,0]\n",
    "        blurred_matrix[:,:,0] += occupancy_mask[:,:,-1]\n",
    "        blurred_matrix[:,:,-1] += occupancy_mask[:,:,0]\n",
    "    # clipping the matrix, tried density stuff here, but can't work.\n",
    "    blurred_matrix[blurred_matrix >= 1] = 1\n",
    "    blurred_matrix[blurred_matrix < 0] = 0 # the amount of neighbours is 27 at most    \n",
    "    # obtaining the contours\n",
    "    contour_mask = blurred_matrix - occupancy_mask\n",
    "    return contour_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_preparing(array):\n",
    "    mask_cluster_state_mask = np.array((array,\n",
    "                                    np.zeros(array.shape),\n",
    "                                    np.zeros(array.shape)))\n",
    "    #mask_cluster_state_mask = pbcarray(mask_cluster_state_mask)\n",
    "    temp_mask_indices = np.where(array == 1)\n",
    "    mask_indices = np.array(list(zip(*temp_mask_indices)),dtype=int)\n",
    "    \n",
    "    return mask_cluster_state_mask, mask_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cubic_selection(dimensions, position, distance = 1):\n",
    "    \"\"\"Creates a selection mask which can handle cubic pbc.\"\"\"\n",
    "    position = np.array(position)\n",
    "    selection = np.array((position-distance, position+distance+1)).T\n",
    "    #print('unmodified selection', selection)\n",
    "    selection_list = []\n",
    "    # create the non continuous axes for the 3 cases (too low,high, or normal)\n",
    "    for axes, single_selection in enumerate(selection):\n",
    "        #print('axes {} selection unmodified'.format(axes), single_selection)\n",
    "        if single_selection[0] < 0:\n",
    "            single_selection = (single_selection[1], dimensions[axes]+single_selection[0])\n",
    "            temp_ones = np.ones(dimensions[axes])\n",
    "            temp_ones[single_selection[0]:single_selection[1]] = 0\n",
    "            #print(temp_ones)\n",
    "            axes_selection = np.array(np.where(temp_ones)).flatten()\n",
    "            #print('axes {} selection modified 1'.format(axes), single_selection)\n",
    "            #print(axes_selection)\n",
    "        elif single_selection[1] >= dimensions[axes]:\n",
    "            single_selection = (single_selection[1] % (dimensions[axes]), single_selection[0])\n",
    "            temp_ones = np.ones(dimensions[axes])\n",
    "            temp_ones[single_selection[0]:single_selection[1]] = 0\n",
    "            axes_selection = np.array(np.where(temp_ones)).flatten()\n",
    "            #print('axes {} selection modified 2'.format(axes), single_selection)\n",
    "            #print(axes_selection)\n",
    "        else:\n",
    "            axes_selection = np.arange(single_selection[0], single_selection[1]).flatten()\n",
    "            #print('axes {} selection modified 3'.format(axes), single_selection)\n",
    "            #print(axes_selection)\n",
    "        selection_list.append(axes_selection)\n",
    "    # create the coordinates for the neighbours in the non continous selection\n",
    "    selection_mask = np.zeros(dimensions)\n",
    "    for element in list(itertools.product(selection_list[0], selection_list[1], selection_list[2])):\n",
    "        selection_mask[element] = 1\n",
    "    return np.array(np.where(selection_mask == 1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_inner_loop(idx, mask_cluster_state_mask, counter, to_do_list, distance, pbc = True):\n",
    "    \"\"\"A pretty smart clustering procedure.\"\"\"\n",
    "    # this automagically never flies out of bounds :D\n",
    "    # this is also wher I have to implement PBC lets start with cbic\n",
    "    #  the goal is to make the mask select the other side edges for negative numbers\n",
    "    min_distance = idx - distance\n",
    "    max_distance = idx + distance + 1\n",
    "    simple_indices = np.logical_and(np.all(min_distance >= 0),\n",
    "                            np.all(max_distance <= mask_cluster_state_mask.shape[1:]))\n",
    "    # either no pbc, or the indexes are not an issue without pbc treatment\n",
    "    if not pbc or simple_indices:\n",
    "        neighbour_hits = mask_cluster_state_mask[:3, min_distance[0]:max_distance[0], \n",
    "                                                     min_distance[1]:max_distance[1], \n",
    "                                                     min_distance[2]:max_distance[2]]\n",
    "        # This is where some cool masks are made for detection of neighbours\n",
    "        neighbour_coordinates = neighbour_hits[0].astype(bool) # where?\n",
    "        neighbour_clusters = neighbour_hits[1] # ref to cluster positions\n",
    "        neighbour_clusters[neighbour_coordinates] = counter # set clusters for found neighbours\n",
    "        neighbour_states = neighbour_hits[2].astype(bool) # check state of neighbour\n",
    "            \n",
    "        # if you are a neighbour and you have not been placed in the queue\n",
    "        new_coordinates = np.where(neighbour_coordinates & ~neighbour_states)\n",
    "        new_coordinates = np.array(new_coordinates).T\n",
    "        try:\n",
    "            # transform local to world coordinates\n",
    "            new_coordinates = new_coordinates + idx - (1,1,1)\n",
    "        except ValueError:\n",
    "            return\n",
    "        # add the global coordinates of the next iterations\n",
    "        to_do_list.extend(new_coordinates)\n",
    "        # setting all the neighbours to hit so they will never \n",
    "        #  be done again\n",
    "        neighbour_hits[2, :] = 1\n",
    "    elif pbc:\n",
    "        neighbour_coordinates = cubic_selection(mask_cluster_state_mask.shape[1:], idx, distance)\n",
    "        for neighbour_coordinate in neighbour_coordinates:\n",
    "            # find occupied voxels this is either 0 or 1\n",
    "            neighbour_hit = mask_cluster_state_mask[0,\n",
    "                                                     neighbour_coordinate[0],\n",
    "                                                     neighbour_coordinate[1],\n",
    "                                                     neighbour_coordinate[2]]\n",
    "            if neighbour_hit == 1:\n",
    "                # set cluster \n",
    "                mask_cluster_state_mask[1,\n",
    "                                         neighbour_coordinate[0],\n",
    "                                         neighbour_coordinate[1],\n",
    "                                         neighbour_coordinate[2]] = counter\n",
    "                # append to queue if not touched before\n",
    "                if mask_cluster_state_mask[2,\n",
    "                                         neighbour_coordinate[0],\n",
    "                                         neighbour_coordinate[1],\n",
    "                                         neighbour_coordinate[2]] == 0:\n",
    "                    to_do_list.append(neighbour_coordinate)\n",
    "                # set touched state\n",
    "                mask_cluster_state_mask[2,\n",
    "                                         neighbour_coordinate[0],\n",
    "                                         neighbour_coordinate[1],\n",
    "                                         neighbour_coordinate[2]] = 1\n",
    "    # this is probably not what the user had in mind\n",
    "    else:\n",
    "        print(idx, ' could not be processed with the current pbc settings.')\n",
    "\n",
    "    \n",
    "#def clustering_PBC_cubic(mask_cluster_state_mask, to_do_lis, pbc_voxels):\n",
    "#    \"\"\"Fixes cubic pbc by checking the boundary planes for particles and doing a very cheap neighbour search\n",
    "#    at the other side of the PBC plane. Then it adds the found pbc partners to the queue.\n",
    "#    This could probably be made more general to work for all PBC variants in 3d space.\"\"\"\n",
    "#    selected_plane = np.array(np.where(mask_cluster_state_mask[0] == 1)).T\n",
    "#    for pbc_voxel in selected_plane:\n",
    "#        to_do_list.append(border_voxel[0]-1 % , border_voxel[1], border_voxel[2])\n",
    "#    return selected_plane\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the inner logic solid for clustering\n",
    "def clustering(array, distance = 1, pbc = True):\n",
    "    \"\"\"Takes an index (xyz tuple) and uses the neighbour_mask (array) to search for neighbours in the\n",
    "    edge_cluster_mask. It also sets the the touched flag in place in the edge_cluster_state_mask. For all found\n",
    "    and processed neighbours\n",
    "    \n",
    "    ### The matrix need to have no edges in its outer boundary therefore we cheat and add on to all x y z\n",
    "    ### we need to do this before\n",
    "    \"\"\"\n",
    "    mask_cluster_state_mask, mask_indices = clustering_preparing(array)\n",
    "    # the beginning of the outer cluster loop\n",
    "    counter = 0\n",
    "    #time = 0 \n",
    "    max_time = len(mask_indices)\n",
    "    for idx in mask_indices:\n",
    "        # genreates a dequeue, which is like a list but cheaper tot pop at front \n",
    "        to_do_list = collections.deque()\n",
    "        self_state = mask_cluster_state_mask[2, idx[0], idx[1], idx[2]]\n",
    "        if self_state == 0:\n",
    "            counter += 1\n",
    "            # execute cluster function and start queue for cluster\n",
    "            clustering_inner_loop(idx, mask_cluster_state_mask, counter, to_do_list, distance, pbc)\n",
    "        while len(to_do_list) > 0: # exhaust all queue members for cluster\n",
    "            idx = np.array(to_do_list.popleft())\n",
    "            clustering_inner_loop(idx, mask_cluster_state_mask, counter, to_do_list, distance, pbc)\n",
    "    clusters = list(set(mask_cluster_state_mask[1].flatten())) # a set is always returned low to high?\n",
    "    finish = datetime.datetime.now()\n",
    "    return mask_cluster_state_mask, clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_voxels(array):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.gca(projection='3d')\n",
    "    max_size = np.array(array.shape).max()\n",
    "    ax.set_xlim(0,max_size)\n",
    "    ax.set_ylim(0,max_size)\n",
    "    ax.set_zlim(0,max_size)    \n",
    "    color = (0.5,0.5,0.5,0.3)\n",
    "    edge_color = (1,1,1,0.3)\n",
    "    ax.voxels(array, edgecolor=edge_color, facecolor= color)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(array, clusters, min_cluster_size = 5):\n",
    "    \"\"\"Creates a voxel plot for the clusters in the array never plots cluster 0 and only\n",
    "    shows clusters of size equal or larger than the minimum.\"\"\"\n",
    "    edge_color = np.array((1,1,1,0.3), dtype=float)\n",
    "    color = np.array((1,1,1,0.3), dtype=float)\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.gca(projection='3d')\n",
    "    max_size = np.array(array.shape).max()\n",
    "    ax.set_xlim(0,max_size)\n",
    "    ax.set_ylim(0,max_size)\n",
    "    ax.set_zlim(0,max_size)\n",
    "    counter = 0\n",
    "    colors = []\n",
    "    for cluster in clusters:\n",
    "        # automagically skips cluster 0 :D\n",
    "        plot_array = copy.copy(array[1])\n",
    "        plot_array[plot_array != cluster] = 0\n",
    "        plot_array[plot_array > 0] = cluster\n",
    "        color[:3] = np.random.rand(3)\n",
    "        if np.count_nonzero(plot_array.flatten()) >= min_cluster_size:\n",
    "            colors.append(copy.copy(color))\n",
    "            counter += 1\n",
    "            ax.voxels(plot_array, edgecolor=edge_color, facecolors = color)\n",
    "    print('{} cluster(s) have been found >= {} (min_cluster_size)'.format(counter, min_cluster_size))\n",
    "    plt.show()\n",
    "    counter = 0\n",
    "    for cluster in clusters:\n",
    "        plot_array = copy.copy(array[1])\n",
    "        plot_array[plot_array != cluster] = 0\n",
    "        plot_array[plot_array > 0] = cluster\n",
    "        if np.count_nonzero(plot_array.flatten()) >= min_cluster_size:\n",
    "            color = colors[counter]\n",
    "            counter += 1\n",
    "            print('Cluster {}'.format(counter))\n",
    "            fig = plt.figure(figsize=(10, 10))\n",
    "            ax = fig.gca(projection='3d')\n",
    "            max_size = np.array(array.shape).max()\n",
    "            ax.set_xlim(0,max_size)\n",
    "            ax.set_ylim(0,max_size)\n",
    "            ax.set_zlim(0,max_size)\n",
    "            ax.voxels(plot_array, edgecolor=edge_color, facecolors = color)\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
