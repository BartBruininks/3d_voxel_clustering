{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MDclustering \n",
    "#### An attempt of making data analysis easier and quicker for many MD people\n",
    "\n",
    "## MAIN GOAL\n",
    "To do analysis of MD trajectory on a more abstract level. Instead of having to talk about specific atoms and their corresponding position and residue members. We often would like to talk about properties on a much more abstract level, such as the diffusion of a certain aggregate of particles, or talk about the leaflets of lipid assemblies. Current methods for leaflet identification often imply geometrical arguments  on every residue, which can quickly become very expensive. Here we present a mixture of voxel and graph based selection methods to obtain information about dynamic clusters at a (hopefully) realtime speed.\n",
    "\n",
    "### Clustering\n",
    "#### CONTOURS\n",
    "Contours are meant for analysis on the behaviour of clusters in a cheaper dimensionality. They could be enough to uniquely identify a cluster e.g. the number of particles present and the voxel space contour size (not exactly the real size, but often close enough).\n",
    "\n",
    "#### VOLUMES\n",
    "Volumes give you a more robust manner of selection which will for sure include all the particles you need for high resolution analysis. Combining layers of volumes and contours often can dramatically reduce the degrees of freedom in your data set, without loosing any particles on the way. Hopefully we will demonstrate this for the automatic leaflet detection in a crowded membrane space (all forms of lipid cluster states, such as: adhesed, semi-fused, fused and seperated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bart/projects/virtual-python3-environments/clustering/lib/python3.6/site-packages/MDAnalysis/topology/guessers.py:72: UserWarning: Failed to guess the mass for the following atom types: D\n",
      "  warnings.warn(\"Failed to guess the mass for the following atom types: {}\".format(atom_type))\n",
      "/home/bart/projects/virtual-python3-environments/clustering/lib/python3.6/site-packages/MDAnalysis/topology/guessers.py:72: UserWarning: Failed to guess the mass for the following atom types: G\n",
      "  warnings.warn(\"Failed to guess the mass for the following atom types: {}\".format(atom_type))\n",
      "/home/bart/projects/virtual-python3-environments/clustering/lib/python3.6/site-packages/MDAnalysis/topology/guessers.py:72: UserWarning: Failed to guess the mass for the following atom types: T\n",
      "  warnings.warn(\"Failed to guess the mass for the following atom types: {}\".format(atom_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110861 particles to cluster.\n",
      "The average bin density is 6.07\n",
      "Plotting the density mask:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Though hard to see, the density of the lipoplex is connected to the bilayer through its pbc upper limit.\n",
      "\n",
      "The density cluster(s):\n",
      "It took 0:00:01.114734 (days:hours:seconds:decimals) to do the clustering.\n",
      "1 cluster(s) have been found:\n",
      "1 cluster(s) have been found >= 1 (min_cluster_size)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The density of the lipoplex is connected to the bilayer through its pbc upper limit. This causes the volumes to be one cluster. If one would like to seperate such cases, selecting only the lipid tails will result in two seperate entities.\n",
      "\n",
      "Plotting the contour mask:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "As a result from the connected densities, the contour of the lipoplex is connected to the bilayer lower leafet through its pbc upper limit. This causes those contours to be one cluster. If one would like to seperate such cases, selecting only the lipid tails will result in two separate entities.\n",
      "\n",
      "The contour cluster(s):\n",
      "It took 0:00:00.410952 (days:hours:seconds:decimals) to do the clustering.\n",
      "7 cluster(s) have been found:\n",
      "7 cluster(s) have been found >= 1 (min_cluster_size)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "As we can see, we can get a correct selecion for the inner channels of the lipopoplex. We are also capable to seperate the two leaflets. We also cluster over PBC, however, the phosphate densities of two non-fused approximate bilayers is not resolved correctly to allow for leaflet detection in such cases. We are currently working on a more advanced procedure to allow for such cases. Nevertheless, we believe that in many cases the above demonstrated procedure could help a lot! \n",
      "\n",
      "Basically, its an overhaul of MDAnalysis.leaflet. An implementation of the contour part on top of the MDA.leaflet algorythm could/should achieve the same result.\n"
     ]
    }
   ],
   "source": [
    "#from pbcpy.base import pbcarray # needed for pbc clustering\n",
    "import MDAnalysis as mda\n",
    "import numpy as np\n",
    "import copy\n",
    "#import nglview as nv\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "# allows for realtime plot rendering in notebook\n",
    "#%matplotlib notebook\n",
    "import itertools\n",
    "import collections\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "### initial settings\n",
    "# sets the resolution of the bins the amount in (nm/resolution)*3 is the minimum cluster distance at\n",
    "#  which seperation is detected\n",
    "#resolution = float(sys.argv[1])\n",
    "resolution = 1\n",
    "#the density is the ratio of the mean of the occupancy of occupied bins\n",
    "#density = float(sys.argv[2])\n",
    "# The density can be useful to make a distinction between edge paticles and bulk.  \n",
    "#  The inverse tag allows you to select only the not dense regions and not 0.\n",
    "density = 0.01\n",
    "inv_density = False\n",
    "#blur_density = 1 # the amount of neighbours is 27 at most\n",
    "# warning setting the smearing from hard boundary to soft, results in good clustering,\n",
    "#  but probably bad underlying particle restults, use with care!!! (we are going to use this for leaflet\n",
    "#  detection)\n",
    "#  show plots or not\n",
    "plotting = True\n",
    "min_cluster_size = 1\n",
    "\n",
    "### Data, later this will be taken from MDAnalysis\n",
    "#test_data = np.genfromtxt('attached_tails.dat')\n",
    "#test_data = np.genfromtxt('ball.dat')\n",
    "#test_data = np.array([[0,0,0],[0,1,0],[1,1,0],[1,0,0],[2,0,0],[2,1,0],\n",
    "#                      [2,2,0],[0,2,0],[1,2,0],[0,0,1],[0,1,1],[1,1,1],[1,0,1],\n",
    "#                      [2,0,1],[2,0,1],[2,1,1],[2,2,1],[0,0,2],[2,0,1],\n",
    "#                      [0,1,2],[1,1,2],[1,0,2],[2,0,2],[2,0,2],[2,1,2],[2,2,2],\n",
    "#                      [0,2,2],[1,2,2],[0,2,1],[1,2,1],\n",
    "#                      [10,10,0], [10,11,0], [5,3,0],[3,5,0], [4,4,0],[4,5,0], [15,15,0]])\n",
    "\n",
    "\n",
    "# generating test data MDA\n",
    "u = mda.Universe('test_files/em.gro')\n",
    "lipoplex_lipids = u.select_atoms('resname DOPE or resname DOTAP')\n",
    "test_data = lipoplex_lipids.positions/10\n",
    "print('{} particles to cluster.'.format(test_data.shape[0]))\n",
    "\n",
    "\n",
    "#### This is where it all happens\n",
    "def generate_explicit_matrix(array, resolution, density, \n",
    "                             specified_dim = False, inv_density = False, no_zero = True):\n",
    "    \"\"\"Takes a compressed 3d matrix and returns it as an explicit 3d matrix.\n",
    "    The resolution is the relative bin size. A tuple of 3 can be used to speify the\n",
    "    binning dimensions  in nm. It assumes your box has cubic PBC! Density can be used to \n",
    "    specify a minimum voxel density to be added to the output matrix. The inv_density can\n",
    "    be set to true to specify a maximum density. The no_zero flag will even under the inv_density\n",
    "    setting not return the elements containing 0 elements.\"\"\"\n",
    "    # we want to refer to the unmodified array for the dictionary entries later on\n",
    "    array_original = copy.copy(array)\n",
    "    # find the extremes to determine the final size of the explicit binned matrix\n",
    "    x_max, y_max, z_max = np.max(array[:,0]), np.max(array[:,1]), np.max(array[:,2])\n",
    "    if not specified_dim:\n",
    "        limits = np.array([x_max, y_max, z_max])\n",
    "    else:\n",
    "        limits = np.array(specified_dim)\n",
    "    # adapting the binning to the resolution\n",
    "    limits = limits/resolution\n",
    "    limits_ints = np.array(np.round(limits), dtype=int)\n",
    "    # making the explicit matrix\n",
    "    explicit_matrix = np.zeros(limits_ints)\n",
    "    # converting the data points\n",
    "    array_original = array\n",
    "    array = copy.copy(array_original)\n",
    "    array = array/resolution # convert data to bins\n",
    "    # creating a dicitonary with the atoms inside and the xyz coodirdiantes as keys\n",
    "    voxel2atoms = collections.defaultdict(list)\n",
    "    # adding each poin to the explicit matrix also cubic PBC!!!\n",
    "    for idx, point in enumerate(array):\n",
    "        # warning this implements cubic PBC!!! A similar trick can be done for others\n",
    "        x = round(point[0] % (limits_ints[0]-1)).astype(int)\n",
    "        y = round(point[1] % (limits_ints[1]-1)).astype(int)\n",
    "        z = round(point[2] % (limits_ints[2]-1)).astype(int)\n",
    "        #print(x, type(x), y, type(y), z ,type(z))\n",
    "        explicit_matrix[x, y, z] += 1\n",
    "        # mapping atoms to voxels\n",
    "        key = 'x{}y{}z{}'.format(x, y, z)\n",
    "        voxel2atoms[key].append(array_original[idx])\n",
    "    mean = explicit_matrix[explicit_matrix > 0].flatten().mean()\n",
    "    print('The average bin density is {:.2f}'.format(mean))\n",
    "    # clipping the matrix using the specified density or the inverse\n",
    "    if inv_density:\n",
    "        if no_zero:\n",
    "            explicit_matrix[explicit_matrix == 0 ] = density*mean + 1\n",
    "        explicit_matrix[explicit_matrix <= density*mean] = 1\n",
    "        explicit_matrix[explicit_matrix > density*mean] = 0 \n",
    "    else:\n",
    "        explicit_matrix[explicit_matrix < density*mean] = 0 \n",
    "        explicit_matrix[explicit_matrix >= density*mean] = 1\n",
    "    return explicit_matrix, voxel2atoms\n",
    "\n",
    "def smear_3d_matrix(array, pbc = True):\n",
    "    \"\"\"Takes an explicit array and smears it over the axes. This is like\n",
    "    a running average in 3D. It returns the smeared array as a new array.\n",
    "    By default the pbc is taken to be cubic, this can be turned off.\n",
    "    \n",
    "    !!! the smearing does not take pbc into account yet !!!\"\"\"\n",
    "    shift = 1\n",
    "    # making the matrix one bigger to prevent problems later on\n",
    "    #dimensions = np.array(array.shape)+np.array((2, 2, 2))\n",
    "    #array_empty = np.zeros(dimensions)\n",
    "    #array_empty[1:-1,1:-1,1:-1] = array\n",
    "    occupancy_mask = copy.copy(array)\n",
    "    # inverting the matrix to get the inner boundaries\n",
    "    occupancy_mask = np.array(np.logical_not(occupancy_mask),dtype=float)\n",
    "    # smearing the matrix\n",
    "    blurred_matrix = copy.copy(occupancy_mask)\n",
    "    blurred_matrix[shift:] += occupancy_mask[:-shift]\n",
    "    blurred_matrix[:-shift] += occupancy_mask[shift:]\n",
    "    blurred_matrix[:,shift:] += occupancy_mask[:,:-shift]\n",
    "    blurred_matrix[:,:-shift] += occupancy_mask[:,shift:]\n",
    "    blurred_matrix[:,:,shift:] += occupancy_mask[:,:,:-shift]\n",
    "    blurred_matrix[:,:,:-shift] += occupancy_mask[:,:,shift:]\n",
    "    # smearing the pbc boundaries for cubic pbc\n",
    "    if pbc:\n",
    "        blurred_matrix[0] += occupancy_mask[-1]\n",
    "        blurred_matrix[-1] += occupancy_mask[0]\n",
    "        blurred_matrix[:,0] += occupancy_mask[:,-1]\n",
    "        blurred_matrix[:,-1] += occupancy_mask[:,0]\n",
    "        blurred_matrix[:,:,0] += occupancy_mask[:,:,-1]\n",
    "        blurred_matrix[:,:,-1] += occupancy_mask[:,:,0]\n",
    "    # clipping the matrix, tried density stuff here, but can't work.\n",
    "    blurred_matrix[blurred_matrix >= 1] = 1\n",
    "    blurred_matrix[blurred_matrix < 0] = 0 # the amount of neighbours is 27 at most    \n",
    "    # obtaining the contours\n",
    "    contour_mask = blurred_matrix - occupancy_mask\n",
    "    return contour_mask\n",
    "\n",
    "def clustering_preparing(array):\n",
    "    mask_cluster_state_mask = np.array((array,\n",
    "                                    np.zeros(array.shape),\n",
    "                                    np.zeros(array.shape)))\n",
    "    #mask_cluster_state_mask = pbcarray(mask_cluster_state_mask)\n",
    "    temp_mask_indices = np.where(array == 1)\n",
    "    mask_indices = np.array(list(zip(*temp_mask_indices)),dtype=int)\n",
    "    \n",
    "    return mask_cluster_state_mask, mask_indices\n",
    "\n",
    "def cubic_selection(dimensions, position, distance = 1):\n",
    "    \"\"\"Creates a selection mask which can handle cubic pbc.\"\"\"\n",
    "    position = np.array(position)\n",
    "    selection = np.array((position-distance, position+distance+1)).T\n",
    "    #print('unmodified selection', selection)\n",
    "    selection_list = []\n",
    "    # create the non continuous axes for the 3 cases (too low,high, or normal)\n",
    "    for axes, single_selection in enumerate(selection):\n",
    "        #print('axes {} selection unmodified'.format(axes), single_selection)\n",
    "        if single_selection[0] < 0:\n",
    "            single_selection = (single_selection[1], dimensions[axes]+single_selection[0])\n",
    "            temp_ones = np.ones(dimensions[axes])\n",
    "            temp_ones[single_selection[0]:single_selection[1]] = 0\n",
    "            #print(temp_ones)\n",
    "            axes_selection = np.array(np.where(temp_ones)).flatten()\n",
    "            #print('axes {} selection modified 1'.format(axes), single_selection)\n",
    "            #print(axes_selection)\n",
    "        elif single_selection[1] >= dimensions[axes]:\n",
    "            single_selection = (single_selection[1] % (dimensions[axes]), single_selection[0])\n",
    "            temp_ones = np.ones(dimensions[axes])\n",
    "            temp_ones[single_selection[0]:single_selection[1]] = 0\n",
    "            axes_selection = np.array(np.where(temp_ones)).flatten()\n",
    "            #print('axes {} selection modified 2'.format(axes), single_selection)\n",
    "            #print(axes_selection)\n",
    "        else:\n",
    "            axes_selection = np.arange(single_selection[0], single_selection[1]).flatten()\n",
    "            #print('axes {} selection modified 3'.format(axes), single_selection)\n",
    "            #print(axes_selection)\n",
    "        selection_list.append(axes_selection)\n",
    "    # create the coordinates for the neighbours in the non continous selection\n",
    "    selection_mask = np.zeros(dimensions)\n",
    "    for element in list(itertools.product(selection_list[0], selection_list[1], selection_list[2])):\n",
    "        selection_mask[element] = 1\n",
    "    return np.array(np.where(selection_mask == 1)).T\n",
    "\n",
    "def clustering_inner_loop(idx, mask_cluster_state_mask, counter, to_do_list, distance, pbc = True):\n",
    "    \"\"\"A pretty smart clustering procedure.\"\"\"\n",
    "    # this automagically never flies out of bounds :D\n",
    "    # this is also wher I have to implement PBC lets start with cbic\n",
    "    #  the goal is to make the mask select the other side edges for negative numbers\n",
    "    min_distance = idx - distance\n",
    "    max_distance = idx + distance + 1\n",
    "    simple_indices = np.logical_and(np.all(min_distance >= 0),\n",
    "                            np.all(max_distance <= mask_cluster_state_mask.shape[1:]))\n",
    "    # either no pbc, or the indexes are not an issue without pbc treatment\n",
    "    if not pbc or simple_indices:\n",
    "        neighbour_hits = mask_cluster_state_mask[:3, min_distance[0]:max_distance[0], \n",
    "                                                     min_distance[1]:max_distance[1], \n",
    "                                                     min_distance[2]:max_distance[2]]\n",
    "        # This is where some cool masks are made for detection of neighbours\n",
    "        neighbour_coordinates = neighbour_hits[0].astype(bool) # where?\n",
    "        neighbour_clusters = neighbour_hits[1] # ref to cluster positions\n",
    "        neighbour_clusters[neighbour_coordinates] = counter # set clusters for found neighbours\n",
    "        neighbour_states = neighbour_hits[2].astype(bool) # check state of neighbour\n",
    "            \n",
    "        # if you are a neighbour and you have not been placed in the queue\n",
    "        new_coordinates = np.where(neighbour_coordinates & ~neighbour_states)\n",
    "        new_coordinates = np.array(new_coordinates).T\n",
    "        try:\n",
    "            # transform local to world coordinates\n",
    "            new_coordinates = new_coordinates + idx - (1,1,1)\n",
    "        except ValueError:\n",
    "            return\n",
    "        # add the global coordinates of the next iterations\n",
    "        to_do_list.extend(new_coordinates)\n",
    "        # setting all the neighbours to hit so they will never \n",
    "        #  be done again\n",
    "        neighbour_hits[2, :] = 1\n",
    "    elif pbc:\n",
    "        neighbour_coordinates = cubic_selection(mask_cluster_state_mask.shape[1:], idx, distance)\n",
    "        for neighbour_coordinate in neighbour_coordinates:\n",
    "            # find occupied voxels this is either 0 or 1\n",
    "            neighbour_hit = mask_cluster_state_mask[0,\n",
    "                                                     neighbour_coordinate[0],\n",
    "                                                     neighbour_coordinate[1],\n",
    "                                                     neighbour_coordinate[2]]\n",
    "            if neighbour_hit == 1:\n",
    "                # set cluster \n",
    "                mask_cluster_state_mask[1,\n",
    "                                         neighbour_coordinate[0],\n",
    "                                         neighbour_coordinate[1],\n",
    "                                         neighbour_coordinate[2]] = counter\n",
    "                # append to queue if not touched before\n",
    "                if mask_cluster_state_mask[2,\n",
    "                                         neighbour_coordinate[0],\n",
    "                                         neighbour_coordinate[1],\n",
    "                                         neighbour_coordinate[2]] == 0:\n",
    "                    to_do_list.append(neighbour_coordinate)\n",
    "                # set touched state\n",
    "                mask_cluster_state_mask[2,\n",
    "                                         neighbour_coordinate[0],\n",
    "                                         neighbour_coordinate[1],\n",
    "                                         neighbour_coordinate[2]] = 1\n",
    "    # this is probably not what the user had in mind\n",
    "    else:\n",
    "        print(idx, ' could not be processed with the current pbc settings.')\n",
    "\n",
    "    \n",
    "#def clustering_PBC_cubic(mask_cluster_state_mask, to_do_lis, pbc_voxels):\n",
    "#    \"\"\"Fixes cubic pbc by checking the boundary planes for particles and doing a very cheap neighbour search\n",
    "#    at the other side of the PBC plane. Then it adds the found pbc partners to the queue.\n",
    "#    This could probably be made more general to work for all PBC variants in 3d space.\"\"\"\n",
    "#    selected_plane = np.array(np.where(mask_cluster_state_mask[0] == 1)).T\n",
    "#    for pbc_voxel in selected_plane:\n",
    "#        to_do_list.append(border_voxel[0]-1 % , border_voxel[1], border_voxel[2])\n",
    "#    return selected_plane\n",
    "        \n",
    "\n",
    "# getting the inner logic solid for clustering\n",
    "def clustering(array, distance = 1, pbc = True):\n",
    "    \"\"\"Takes an index (xyz tuple) and uses the neighbour_mask (array) to search for neighbours in the\n",
    "    edge_cluster_mask. It also sets the the touched flag in place in the edge_cluster_state_mask. For all found\n",
    "    and processed neighbours\n",
    "    \n",
    "    ### The matrix need to have no edges in its outer boundary therefore we cheat and add on to all x y z\n",
    "    ### we need to do this before\n",
    "    \"\"\"\n",
    "    start = datetime.datetime.now()\n",
    "    mask_cluster_state_mask, mask_indices = clustering_preparing(array)\n",
    "    # the beginning of the outer cluster loop\n",
    "    counter = 0\n",
    "    #time = 0 \n",
    "    max_time = len(mask_indices)\n",
    "    for idx in mask_indices:\n",
    "        # genreates a dequeue, which is like a list but cheaper tot pop at front \n",
    "        to_do_list = collections.deque()\n",
    "        self_state = mask_cluster_state_mask[2, idx[0], idx[1], idx[2]]\n",
    "        if self_state == 0:\n",
    "            counter += 1\n",
    "            # execute cluster function and start queue for cluster\n",
    "            clustering_inner_loop(idx, mask_cluster_state_mask, counter, to_do_list, distance, pbc)\n",
    "        while len(to_do_list) > 0: # exhaust all queue members for cluster\n",
    "            idx = np.array(to_do_list.popleft())\n",
    "            clustering_inner_loop(idx, mask_cluster_state_mask, counter, to_do_list, distance, pbc)\n",
    "    clusters = list(set(mask_cluster_state_mask[1].flatten())) # a set is always returned low to high?\n",
    "    finish = datetime.datetime.now()\n",
    "    print('It took {} (days:hours:seconds:decimals) to do the clustering.'.format(finish-start))\n",
    "    print('{} cluster(s) have been found:'.format(len(clusters)-1))\n",
    "    return mask_cluster_state_mask, clusters\n",
    "\n",
    "def plot_voxels(array):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.gca(projection='3d')\n",
    "    max_size = np.array(array.shape).max()\n",
    "    ax.set_xlim(0,max_size)\n",
    "    ax.set_ylim(0,max_size)\n",
    "    ax.set_zlim(0,max_size)    \n",
    "    color = (0.5,0.5,0.5,0.3)\n",
    "    edge_color = (1,1,1,0.3)\n",
    "    ax.voxels(array, edgecolor=edge_color, facecolor= color)\n",
    "    plt.show()\n",
    "    \n",
    "            \n",
    "def plot_clusters(array, clusters, min_cluster_size = 5):\n",
    "    \"\"\"Creates a voxel plot for the clusters in the array never plots cluster 0 and only\n",
    "    shows clusters of size equal or larger than the minimum.\"\"\"\n",
    "    edge_color = np.array((1,1,1,0.3), dtype=float)\n",
    "    color = np.array((1,1,1,0.3), dtype=float)\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.gca(projection='3d')\n",
    "    max_size = np.array(array.shape).max()\n",
    "    ax.set_xlim(0,max_size)\n",
    "    ax.set_ylim(0,max_size)\n",
    "    ax.set_zlim(0,max_size)\n",
    "    counter = 0\n",
    "    colors = []\n",
    "    for cluster in clusters:\n",
    "        # automagically skips cluster 0 :D\n",
    "        plot_array = copy.copy(array[1])\n",
    "        plot_array[plot_array != cluster] = 0\n",
    "        plot_array[plot_array > 0] = cluster\n",
    "        color[:3] = np.random.rand(3)\n",
    "        if np.count_nonzero(plot_array.flatten()) >= min_cluster_size:\n",
    "            colors.append(copy.copy(color))\n",
    "            counter += 1\n",
    "            ax.voxels(plot_array, edgecolor=edge_color, facecolors = color)\n",
    "    print('{} cluster(s) have been found >= {} (min_cluster_size)'.format(counter, min_cluster_size))\n",
    "    plt.show()\n",
    "    counter = 0\n",
    "    for cluster in clusters:\n",
    "        plot_array = copy.copy(array[1])\n",
    "        plot_array[plot_array != cluster] = 0\n",
    "        plot_array[plot_array > 0] = cluster\n",
    "        if np.count_nonzero(plot_array.flatten()) >= min_cluster_size:\n",
    "            color = colors[counter]\n",
    "            counter += 1\n",
    "            print('Cluster {}'.format(counter))\n",
    "            fig = plt.figure(figsize=(10, 10))\n",
    "            ax = fig.gca(projection='3d')\n",
    "            max_size = np.array(array.shape).max()\n",
    "            ax.set_xlim(0,max_size)\n",
    "            ax.set_ylim(0,max_size)\n",
    "            ax.set_zlim(0,max_size)\n",
    "            ax.voxels(plot_array, edgecolor=edge_color, facecolors = color)\n",
    "            plt.show()\n",
    "    \n",
    "### transform the compressed matrix into an explicit matrix\n",
    "explicit_matrix, voxel2atoms = generate_explicit_matrix(test_data, resolution, \n",
    "                                                        density, inv_density = inv_density)\n",
    "if plotting:\n",
    "    print('Plotting the density mask:')\n",
    "    plot_voxels(explicit_matrix)\n",
    "print('\\nThough hard to see, the density of the lipoplex is connected to the bilayer through its pbc upper limit.\\n')\n",
    "    \n",
    "### doing the clustering for the volumes\n",
    "print('The density cluster(s):')\n",
    "density_cluster_state_mask, density_clusters = clustering(explicit_matrix) \n",
    "# plotting the density clusters\n",
    "plot_clusters(density_cluster_state_mask, density_clusters, min_cluster_size)\n",
    "print('\\nThe density of the lipoplex is connected to the bilayer through its pbc upper limit. '\n",
    "      'This causes the volumes to be one cluster. If one would like to seperate such cases, selecting only '\n",
    "      'the lipid tails will result in two seperate entities.\\n')\n",
    "\n",
    "### calculating the contour particles\n",
    "contour_mask = smear_3d_matrix(explicit_matrix)\n",
    "if plotting:\n",
    "    print('Plotting the contour mask:')\n",
    "    plot_voxels(contour_mask)\n",
    "print('\\nAs a result from the connected densities, the contour of the lipoplex is connected to the bilayer '\n",
    "      'lower leafet through its pbc upper limit. '\n",
    "      'This causes those contours to be one cluster. If one would like to seperate such cases, selecting only '\n",
    "      'the lipid tails will result in two separate entities.\\n')\n",
    "\n",
    "### doing the clustering for the contours\n",
    "print('The contour cluster(s):')\n",
    "contour_cluster_state_mask, contour_clusters = clustering(contour_mask)\n",
    "# plotting the contour clusters\n",
    "plot_clusters(contour_cluster_state_mask, contour_clusters, min_cluster_size)\n",
    "print('\\nAs we can see, we can get a correct selecion for the inner channels of the lipopoplex. We are also '\n",
    "      'capable to seperate the two leaflets. We also cluster over PBC, however, the phosphate densities '\n",
    "      'of two non-fused approximate bilayers is not resolved correctly to allow for leaflet detection in '\n",
    "      'such cases. We are currently working on a more advanced procedure to allow for such cases. '\n",
    "      'Nevertheless, we believe that in many cases the above demonstrated procedure could help a lot! \\n\\n'\n",
    "      'Basically, its an overhaul of MDAnalysis.leaflet. An implementation of the contour part on top '\n",
    "      'of the MDA.leaflet algorythm could/should achieve the same result.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
